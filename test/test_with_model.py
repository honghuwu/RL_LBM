#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒå¥½çš„PPOæ¨¡å‹è¿›è¡Œ5000æ­¥æµ‹è¯•
è¾“å‡ºå¹³å‡å¥–åŠ±å’Œå¥–åŠ±æ›²çº¿å›¾
"""

import numpy as np
import matplotlib.pyplot as plt
import os
import sys
from stable_baselines3 import PPO
from gymnasium.wrappers import TimeLimit

# æ·»åŠ PPOç›®å½•åˆ°Pythonè·¯å¾„ä»¥å¯¼å…¥env_lbm
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'PPO')))
from env_lbm import LBMEnv

def test_with_model(total_steps=5000):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
    
    Args:
        total_steps: æ€»æµ‹è¯•æ­¥æ•°
    """
    # æ¨¡å‹è·¯å¾„
    # ä¿®æ­£è·¯å¾„ï¼šä»testç›®å½•æŒ‡å‘PPOç›®å½•ä¸‹çš„modelsæ–‡ä»¶å¤¹
    model_paths = [
        "../models/final_model.zip",
        "../PPO/models/final_model.zip",
        "../PPO/models/best_model/best_model.zip",
        "../PPO/models/ppo_lbm_model.zip",
        "../PPO/final_model.zip",
        "../PPO/best_model.zip"
    ]
    
    # é€‰æ‹©å¯ç”¨çš„æ¨¡å‹
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if model_path is None:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ï¼")
        print("ğŸ’¡ è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€å­˜åœ¨ï¼š")
        for path in model_paths:
            print(f"   - {path}")
        return
    
    print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºç¯å¢ƒ
    base_env = LBMEnv(config={"max_episode_steps": 200})
    env = TimeLimit(base_env, max_episode_steps=200)
    
    # åŠ è½½æ¨¡å‹
    model = PPO.load(model_path, env=env)
    
    print(f"ğŸ§ª å¼€å§‹ä½¿ç”¨æ¨¡å‹è¿›è¡Œ {total_steps} æ­¥æµ‹è¯•...")
    
    # å­˜å‚¨æµ‹è¯•æ•°æ®
    all_rewards = []
    step_rewards = []
    current_step = 0
    
    obs, info = env.reset()
    
    while current_step < total_steps:
        # ä½¿ç”¨æ¨¡å‹é¢„æµ‹åŠ¨ä½œ
        action, _states = model.predict(obs, deterministic=True)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, reward, terminated, truncated, info = env.step(action)
        
        # è®°å½•å¥–åŠ±
        step_rewards.append(reward)
        current_step += 1
        
        # æ‰“å°è¿›åº¦
        if current_step % 1000 == 0:
            recent_avg = np.mean(step_rewards[-1000:]) if len(step_rewards) >= 1000 else np.mean(step_rewards)
            print(f"   ğŸ“Š æ­¥æ•°: {current_step}/{total_steps} | æœ€è¿‘1000æ­¥å¹³å‡å¥–åŠ±: {recent_avg:.4f}")
        
        # å¦‚æœepisodeç»“æŸï¼Œé‡ç½®ç¯å¢ƒ
        if terminated or truncated:
            obs, info = env.reset()
    
    # è®¡ç®—ç»Ÿè®¡ç»“æœ
    mean_reward = np.mean(step_rewards)
    std_reward = np.std(step_rewards)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ä½¿ç”¨æ¨¡å‹æµ‹è¯•ç»“æœ:")
    print(f"   ğŸ† å¹³å‡å¥–åŠ±: {mean_reward:.6f} Â± {std_reward:.6f}")
    print(f"   ğŸ“ æ€»æ­¥æ•°: {len(step_rewards)}")
    print(f"   ğŸ“ˆ æœ€å¤§å¥–åŠ±: {np.max(step_rewards):.6f}")
    print(f"   ğŸ“‰ æœ€å°å¥–åŠ±: {np.min(step_rewards):.6f}")
    print("=" * 60)
    
    # ç»˜åˆ¶å¥–åŠ±æ›²çº¿
    plt.figure(figsize=(12, 6))
    
    # åŸå§‹å¥–åŠ±æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(step_rewards, alpha=0.7, linewidth=0.5)
    plt.title('ä½¿ç”¨æ¨¡å‹ - æ­¥å¥–åŠ±æ›²çº¿')
    plt.xlabel('æ­¥æ•°')
    plt.ylabel('å¥–åŠ±')
    plt.grid(True, alpha=0.3)
    
    # æ»‘åŠ¨å¹³å‡å¥–åŠ±æ›²çº¿
    plt.subplot(1, 2, 2)
    window_size = 100
    if len(step_rewards) >= window_size:
        moving_avg = np.convolve(step_rewards, np.ones(window_size)/window_size, mode='valid')
        plt.plot(range(window_size-1, len(step_rewards)), moving_avg, 'r-', linewidth=2)
        plt.title(f'ä½¿ç”¨æ¨¡å‹ - {window_size}æ­¥æ»‘åŠ¨å¹³å‡å¥–åŠ±')
    else:
        plt.plot(step_rewards, 'r-', linewidth=2)
        plt.title('ä½¿ç”¨æ¨¡å‹ - å¥–åŠ±æ›²çº¿')
    plt.xlabel('æ­¥æ•°')
    plt.ylabel('å¹³å‡å¥–åŠ±')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('./models/test_with_model_results.png', dpi=300, bbox_inches='tight')
    print("ğŸ“ˆ æµ‹è¯•ç»“æœå›¾å·²ä¿å­˜è‡³ ./models/test_with_model_results.png")
    plt.show()
    
    # å…³é—­ç¯å¢ƒ
    env.close()
    
    return {
        'mean_reward': mean_reward,
        'std_reward': std_reward,
        'step_rewards': step_rewards,
        'total_steps': len(step_rewards)
    }

if __name__ == "__main__":
    try:
        results = test_with_model(total_steps=5000)
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼å¹³å‡å¥–åŠ±: {results['mean_reward']:.6f}")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()