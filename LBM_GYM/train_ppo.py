import gymnasium as gym
import numpy as np
import time
import matplotlib.pyplot as plt
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback, BaseCallback
from stable_baselines3.common.logger import configure
from stable_baselines3.common.env_util import make_vec_env
from gymnasium.wrappers import TimeLimit
from env_lbm import LBMEnv

"""
è®­ç»ƒè„šæœ¬ï¼šä½¿ç”¨ PPO å¼ºåŒ–å­¦ä¹ ç®—æ³•å¯¹ lbm_solver æ§åˆ¶å™¨é€Ÿåº¦è¿›è¡Œä¼˜åŒ–
ç›®æ ‡ï¼šå­¦ä¼šæ§åˆ¶ (vx, vy) æå‡å‡é˜»æ¯” cl / (cd + Îµ)
"""

class ProgressCallback(BaseCallback):
    """
    è‡ªå®šä¹‰å›è°ƒå‡½æ•°ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œæ€§èƒ½æŒ‡æ ‡
    """
    def __init__(self, check_freq: int = 1000, verbose=1):
        super(ProgressCallback, self).__init__(verbose)
        self.check_freq = check_freq
        self.start_time = None
        self.episode_rewards = []
        self.episode_lengths = []
        self.drag_coefficients = []
        self.lift_coefficients = []
        
    def _on_training_start(self) -> None:
        self.start_time = time.time()
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print("=" * 60)
        
    def _on_step(self) -> bool:
        if self.n_calls % self.check_freq == 0:
            # è®¡ç®—è®­ç»ƒè¿›åº¦
            progress = (self.n_calls / self.locals.get('total_timesteps', 100000)) * 100
            elapsed_time = time.time() - self.start_time
            
            # è·å–æœ€è¿‘çš„è®­ç»ƒç»Ÿè®¡ä¿¡æ¯
            if len(self.model.ep_info_buffer) > 0:
                # è·å–æœ€è¿‘å‡ ä¸ªepisodeçš„å¹³å‡reward
                recent_episodes = list(self.model.ep_info_buffer)[-10:]  # æœ€è¿‘10ä¸ªepisode
                recent_rewards = [ep.get('r', 0) for ep in recent_episodes]
                recent_lengths = [ep.get('l', 0) for ep in recent_episodes]
                
                avg_reward = np.mean(recent_rewards) if recent_rewards else 0
                avg_length = np.mean(recent_lengths) if recent_lengths else 0
                latest_reward = recent_rewards[-1] if recent_rewards else 0
                
                self.episode_rewards.append(latest_reward)
                self.episode_lengths.append(recent_lengths[-1] if recent_lengths else 0)
                
                # å°è¯•è·å–ç¯å¢ƒä¿¡æ¯
                cd, cl = 0, 0
                try:
                    if hasattr(self.training_env, 'get_attr'):
                        env_info = self.training_env.get_attr('last_info')[0]
                        if env_info and isinstance(env_info, dict):
                            cd = env_info.get('CD', 0)
                            cl = env_info.get('CL', 0)
                            self.drag_coefficients.append(cd)
                            self.lift_coefficients.append(cl)
                except:
                    pass
                
                # æ‰“å°è¯¦ç»†çš„è®­ç»ƒä¿¡æ¯
                print(f"ğŸ¯ ã€ç¬¬ {self.n_calls:,} æ­¥ã€‘")
                print(f"   ğŸ“ˆ è¿›åº¦: {progress:.1f}% | â±ï¸  ç”¨æ—¶: {elapsed_time:.0f}s")
                print(f"   ğŸ† æœ€æ–°å¥–åŠ±: {latest_reward:.6f}")
                print(f"   ğŸ“Š å¹³å‡å¥–åŠ±(æœ€è¿‘10è½®): {avg_reward:.6f}")
                print(f"   ğŸ“ å¹³å‡é•¿åº¦: {avg_length:.1f} æ­¥")
                if cd != 0 or cl != 0:
                    print(f"   ğŸŒªï¸  é˜»åŠ›ç³»æ•°(CD): {cd:.6f} | å‡åŠ›ç³»æ•°(CL): {cl:.6f}")
                    print(f"   âš¡ å‡é˜»æ¯”(CL/CD): {cl/cd:.4f}" if cd > 0 else "   âš¡ å‡é˜»æ¯”: N/A")
                print("-" * 50)
            else:
                print(f"ğŸ“Š æ­¥æ•°: {self.n_calls:,} | è¿›åº¦: {progress:.1f}% | "
                      f"æ—¶é—´: {elapsed_time:.0f}s | ç­‰å¾…episodeå®Œæˆ...")
                
        return True
    
    def _on_training_end(self) -> None:
        total_time = time.time() - self.start_time
        print("=" * 60)
        print(f"âœ… è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time:.0f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if len(self.episode_rewards) > 0:
            self.plot_training_curves()
    
    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle('PPO è®­ç»ƒè¿‡ç¨‹ç›‘æ§', fontsize=16)
        
        # å¥–åŠ±æ›²çº¿
        if len(self.episode_rewards) > 0:
            axes[0, 0].plot(self.episode_rewards)
            axes[0, 0].set_title('Episode Rewards')
            axes[0, 0].set_xlabel('Episodes')
            axes[0, 0].set_ylabel('Reward')
            axes[0, 0].grid(True)
        
        # Episode é•¿åº¦
        if len(self.episode_lengths) > 0:
            axes[0, 1].plot(self.episode_lengths)
            axes[0, 1].set_title('Episode Lengths')
            axes[0, 1].set_xlabel('Episodes')
            axes[0, 1].set_ylabel('Steps')
            axes[0, 1].grid(True)
        
        # é˜»åŠ›ç³»æ•°
        if len(self.drag_coefficients) > 0:
            axes[1, 0].plot(self.drag_coefficients)
            axes[1, 0].set_title('Drag Coefficient (CD)')
            axes[1, 0].set_xlabel('Episodes')
            axes[1, 0].set_ylabel('CD')
            axes[1, 0].grid(True)
        
        # å‡åŠ›ç³»æ•°
        if len(self.lift_coefficients) > 0:
            axes[1, 1].plot(self.lift_coefficients)
            axes[1, 1].set_title('Lift Coefficient (CL)')
            axes[1, 1].set_xlabel('Episodes')
            axes[1, 1].set_ylabel('CL')
            axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.savefig('./models/training_curves.png', dpi=300, bbox_inches='tight')
        print("ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜è‡³ ./models/training_curves.png")
        plt.show()

def main():
    print("ğŸ”§ åˆå§‹åŒ– LBM å¼ºåŒ–å­¦ä¹ è®­ç»ƒç¯å¢ƒ...")
    
    # åˆ›å»ºç¯å¢ƒå®ä¾‹ï¼Œè®¾ç½®episodeæœ€å¤§é•¿åº¦
    base_env = LBMEnv(config={"max_episode_steps": 200})
    env = TimeLimit(base_env, max_episode_steps=200)  # ç¡®ä¿episodeåœ¨200æ­¥åç»“æŸ
    print("âœ… LBM ç¯å¢ƒåˆ›å»ºæˆåŠŸ (æœ€å¤§episodeé•¿åº¦: 200æ­¥)")

    # é…ç½®æ—¥å¿—è®°å½•å™¨
    new_logger = configure("./models/logs/", ["stdout", "csv", "tensorboard"])
    
    # åˆ›å»º PPO æ¨¡å‹
    model = PPO(
        policy="MlpPolicy",          # ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥æœºç­–ç•¥ç½‘ç»œ
        env=env,                     # ä½¿ç”¨è‡ªå®šä¹‰çš„LBMç¯å¢ƒ
        verbose=1,                   # è¾“å‡ºè®­ç»ƒä¿¡æ¯
        tensorboard_log="./ppo_lbm_tensorboard/",  # Tensorboard æ—¥å¿—ç›®å½•
        learning_rate=3e-4,          # å­¦ä¹ ç‡
        n_steps=2048,                # æ¯æ¬¡æ›´æ–°çš„æ­¥æ•°
        batch_size=64,               # æ‰¹æ¬¡å¤§å°
        n_epochs=10,                 # æ¯æ¬¡æ›´æ–°çš„è½®æ•°
        gamma=0.99,                  # æŠ˜æ‰£å› å­
        gae_lambda=0.95,             # GAE lambda
        clip_range=0.2,              # PPO clip range
        ent_coef=0.01,               # ç†µç³»æ•°
    )
    
    # è®¾ç½®è‡ªå®šä¹‰æ—¥å¿—è®°å½•å™¨
    model.set_logger(new_logger)
    print("âœ… PPO æ¨¡å‹åˆ›å»ºæˆåŠŸ")

    # åˆ›å»ºå›è°ƒå‡½æ•°
    progress_callback = ProgressCallback(check_freq=1000, verbose=1)
    
    eval_callback = EvalCallback(
        env,
        best_model_save_path="./models/best_model/",
        log_path="./models/eval_log/",
        eval_freq=5000,
        deterministic=True,
        render=False,
        verbose=1
    )
    
    # ç»„åˆå›è°ƒå‡½æ•°
    callbacks = [progress_callback, eval_callback]
    
    print("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ“‹ è®­ç»ƒå‚æ•°:")
    print(f"   - æ€»æ­¥æ•°: 100,000")
    print(f"   - å­¦ä¹ ç‡: 3e-4")
    print(f"   - æ‰¹æ¬¡å¤§å°: 64")
    print(f"   - è¯„ä¼°é¢‘ç‡: æ¯ 5,000 æ­¥")
    print(f"   - è¿›åº¦æ›´æ–°: æ¯ 1,000 æ­¥")
    print("=" * 60)

    # è®­ç»ƒæ™ºèƒ½ä½“
    model.learn(
        total_timesteps=50000,      # æ€»è®­ç»ƒæ­¥æ•°
        callback=callbacks,          # å›è°ƒå‡½æ•°åˆ—è¡¨
        progress_bar=True           # æ˜¾ç¤ºè¿›åº¦æ¡
    )

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    model.save("./models/final_model")
    print("\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå·²ä¿å­˜è‡³ ./models/final_model")
    
    # å¯åŠ¨ TensorBoard æç¤º
    print("\nğŸ“Š æŸ¥çœ‹è¯¦ç»†è®­ç»ƒæ—¥å¿—:")
    print("   1. TensorBoard: tensorboard --logdir=./ppo_lbm_tensorboard")
    print("   2. è®­ç»ƒæ›²çº¿: ./models/training_curves.png")
    print("   3. CSV æ—¥å¿—: ./models/logs/progress.csv")

if __name__ == '__main__':
    main()
